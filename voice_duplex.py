# -*- coding: utf-8 -*-
"""
Voice Duplex - –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –≥–æ–ª–æ—Å–æ–≤–æ–π –¥–∏–∞–ª–æ–≥
TTS‚ÜîSTT —Å –±–∞—Ä–¥–∂-–∏–Ω–æ–º –∏ –ø—Ä–∏–≤–∞—Ç–Ω—ã–º –∫–∞–Ω–∞–ª–æ–º "–≤ —É—Ö–æ"
"""

import asyncio
import io
import threading
import time
import queue
from datetime import datetime
from typing import Optional, Callable, Dict, Any
import numpy as np
import sounddevice as sd
from faster_whisper import WhisperModel
import edge_tts
from pydub import AudioSegment
from loguru import logger


class VoiceDuplex:
    """
    –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –≥–æ–ª–æ—Å–æ–≤–æ–π –¥–∏–∞–ª–æ–≥ —Å AI
    - TTS ‚Üí –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å (–æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª)
    - STT ‚Üê –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å (–º–∏–∫—Ä–æ—Ñ–æ–Ω)
    - "–í —É—Ö–æ" –∫–∞–Ω–∞–ª –¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –ø–æ–¥—Å–∫–∞–∑–æ–∫
    - –ë–∞—Ä–¥–∂-–∏–Ω: –∞–≤—Ç–æ-–ø–∞—É–∑–∞ TTS –ø—Ä–∏ —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    
    def __init__(self, 
                 main_output_device: Optional[int] = None,
                 ear_output_device: Optional[int] = None,
                 mic_input_device: Optional[int] = None,
                 response_callback: Optional[Callable] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥—É–ø–ª–µ–∫—Å-–≥–æ–ª–æ—Å–∞
        
        Args:
            main_output_device: –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã—Ö–æ–¥ (CABLE Input –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π)
            ear_output_device: "–í —É—Ö–æ" –∫–∞–Ω–∞–ª (CABLE-B –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –Ω–∞—É—à–Ω–∏–∫–∏)
            mic_input_device: –ú–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            response_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Ä–µ—á–∏
        """
        self.main_output_device = main_output_device
        self.ear_output_device = ear_output_device
        self.mic_input_device = mic_input_device
        self.response_callback = response_callback
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_active = False
        self.is_speaking = False
        self.is_user_speaking = False
        self.tts_queue = queue.Queue()
        self.stt_queue = queue.Queue()
        
        # –ü–æ—Ç–æ–∫–∏
        self.tts_thread = None
        self.stt_thread = None
        self.ear_thread = None
        self.stop_event = threading.Event()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.sample_rate = 16000
        self.frame_duration = 0.1  # 100ms –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–∫–ª–∏–∫–∞
        self.vad_threshold = 0.015  # –ü–æ—Ä–æ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.barge_in_threshold = 0.02  # –ü–æ—Ä–æ–≥ –¥–ª—è –±–∞—Ä–¥–∂-–∏–Ω–∞
        
        # STT –º–æ–¥–µ–ª—å
        self.whisper_model = None
        self._init_whisper()
        
        # –ë–∞—Ä–¥–∂-–∏–Ω —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.barge_in_active = True
        self.tts_paused = False
        self.user_speech_buffer = []
        
        logger.info("Voice Duplex –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _init_whisper(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper –¥–ª—è STT"""
        try:
            self.whisper_model = WhisperModel("tiny", device="cpu", compute_type="int8")
            logger.info("Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –¥–ª—è –¥—É–ø–ª–µ–∫—Å-—Ä–µ–∂–∏–º–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
            self.whisper_model = None
    
    def _find_devices(self):
        """–ü–æ–∏—Å–∫ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤"""
        devices = sd.query_devices()
        
        # –ü–æ–∏—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤—ã—Ö–æ–¥–∞ (CABLE Input)
        if self.main_output_device is None:
            for idx, device in enumerate(devices):
                if device["max_output_channels"] > 0 and "cable" in device["name"].lower():
                    self.main_output_device = idx
                    logger.info(f"–ù–∞–π–¥–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π –≤—ã—Ö–æ–¥: {device['name']}")
                    break
        
        # –ü–æ–∏—Å–∫ "–≤ —É—Ö–æ" –∫–∞–Ω–∞–ª–∞ (CABLE-B –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π)
        if self.ear_output_device is None:
            for idx, device in enumerate(devices):
                if device["max_output_channels"] > 0 and ("cable-b" in device["name"].lower() or 
                                                         "ear" in device["name"].lower()):
                    self.ear_output_device = idx
                    logger.info(f"–ù–∞–π–¥–µ–Ω '–≤ —É—Ö–æ' –∫–∞–Ω–∞–ª: {device['name']}")
                    break
        
        # –ü–æ–∏—Å–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        if self.mic_input_device is None:
            for idx, device in enumerate(devices):
                if device["max_input_channels"] > 0 and ("microphone" in device["name"].lower() or 
                                                       "mic" in device["name"].lower()):
                    self.mic_input_device = idx
                    logger.info(f"–ù–∞–π–¥–µ–Ω –º–∏–∫—Ä–æ—Ñ–æ–Ω: {device['name']}")
                    break
    
    def _detect_user_speech(self, audio: np.ndarray) -> bool:
        """–î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –±–∞—Ä–¥–∂-–∏–Ω–∞"""
        rms = np.sqrt(np.mean(audio ** 2) + 1e-9)
        return rms > self.vad_threshold
    
    def _detect_barge_in(self, audio: np.ndarray) -> bool:
        """–î–µ—Ç–µ–∫—Ü–∏—è –±–∞—Ä–¥–∂-–∏–Ω–∞ (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–±–∏–≤–∞–µ—Ç AI)"""
        rms = np.sqrt(np.mean(audio ** 2) + 1e-9)
        return rms > self.barge_in_threshold
    
    def _stt_worker(self):
        """STT —Ä–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫"""
        frame_len = int(self.sample_rate * self.frame_duration)
        silence_frames_needed = int(0.5 / self.frame_duration)  # 0.5 —Å–µ–∫ —Ç–∏—à–∏–Ω—ã
        
        audio_buffer = []
        silence_count = 0
        speaking = False
        
        try:
            with sd.InputStream(
                device=self.mic_input_device,
                samplerate=self.sample_rate,
                channels=1,
                dtype="float32",
                blocksize=frame_len,
                latency="low"
            ) as stream:
                
                logger.info("STT —Å–ª—É—à–∞–µ—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω...")
                
                while not self.stop_event.is_set():
                    # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ
                    audio_data, _ = stream.read(frame_len)
                    audio_data = audio_data.flatten()
                    
                    # –î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    if self._detect_user_speech(audio_data):
                        audio_buffer.append(audio_data)
                        speaking = True
                        silence_count = 0
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞—Ä–¥–∂-–∏–Ω
                        if self.barge_in_active and self.is_speaking:
                            if self._detect_barge_in(audio_data):
                                logger.info("üé§ –ë–∞—Ä–¥–∂-–∏–Ω: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–±–∏–≤–∞–µ—Ç")
                                self._pause_tts()
                    else:
                        if speaking:
                            silence_count += 1
                            audio_buffer.append(audio_data)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–µ—á–∏
                    if speaking and silence_count >= silence_frames_needed:
                        if audio_buffer:
                            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞—É–¥–∏–æ
                            full_audio = np.concatenate(audio_buffer)
                            
                            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
                            text = self._transcribe_audio(full_audio)
                            if text:
                                self.stt_queue.put(text)
                                logger.info(f"üé§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª: {text}")
                            
                            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                            audio_buffer.clear()
                            speaking = False
                            silence_count = 0
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞
                    if len(audio_buffer) > 100:  # ~10 —Å–µ–∫—É–Ω–¥
                        audio_buffer = audio_buffer[-50:]
                        speaking = False
                        silence_count = 0
                    
                    time.sleep(0.01)
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ STT worker: {e}")
    
    def _transcribe_audio(self, audio: np.ndarray) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ"""
        if self.whisper_model is None:
            return ""
        
        try:
            segments, _ = self.whisper_model.transcribe(
                audio, 
                language="ru", 
                vad_filter=False,
                beam_size=1,
                best_of=1
            )
            text = " ".join(segment.text.strip() for segment in segments)
            return text.strip()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return ""
    
    def _tts_worker(self):
        """TTS —Ä–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫"""
        logger.info("TTS worker –∑–∞–ø—É—â–µ–Ω")
        
        while not self.stop_event.is_set():
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
                text = self.tts_queue.get(timeout=1.0)
                
                if text:
                    self._speak_text(text)
                    
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ TTS worker: {e}")
    
    def _speak_text(self, text: str):
        """–û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return
        
        try:
            self.is_speaking = True
            logger.info(f"üîä AI –≥–æ–≤–æ—Ä–∏—Ç: {text}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Edge TTS
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                audio_data = loop.run_until_complete(self._generate_tts_audio(text))
                
                # –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º –≤—ã—Ö–æ–¥–µ
                if self.main_output_device is not None:
                    sd.play(audio_data, self.sample_rate, device=self.main_output_device, blocking=True)
                
            finally:
                loop.close()
            
            self.is_speaking = False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è: {e}")
            self.is_speaking = False
    
    async def _generate_tts_audio(self, text: str) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS –∞—É–¥–∏–æ"""
        try:
            communicate = edge_tts.Communicate(text, "ru-RU-DmitryNeural", rate="+0%", pitch="+0%")
            mp3_bytes = b""
            
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    mp3_bytes += chunk["data"]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MP3 –≤ PCM
            seg = AudioSegment.from_file(io.BytesIO(mp3_bytes), format="mp3")
            seg = seg.set_frame_rate(self.sample_rate).set_channels(1).set_sample_width(2)
            raw = seg.raw_data
            audio = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0
            
            return audio
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS: {e}")
            return np.array([])
    
    def _ear_worker(self):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è "–≤ —É—Ö–æ" –∫–∞–Ω–∞–ª–∞"""
        logger.info("'–í —É—Ö–æ' –∫–∞–Ω–∞–ª –∑–∞–ø—É—â–µ–Ω")
        
        while not self.stop_event.is_set():
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
                if not self.stt_queue.empty():
                    user_text = self.stt_queue.get_nowait()
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É
                    hint = self._generate_ear_hint(user_text)
                    if hint and self.ear_output_device is not None:
                        self._speak_ear_hint(hint)
                
                time.sleep(0.1)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ ear worker: {e}")
    
    def _generate_ear_hint(self, user_text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Å–∫–∞–∑–∫–∏ "–≤ —É—Ö–æ" –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–¥—Å–∫–∞–∑–æ–∫ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ AI)
        hints = {
            "–∑–∞—Ä–ø–ª–∞—Ç–∞": "üí° –°–ø—Ä–æ—Å–∏ –ø—Ä–æ equity –∏ –±–æ–Ω—É—Å—ã",
            "–æ–ø—ã—Ç": "üí° –†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ Prometheus –ø—Ä–æ–µ–∫—Ç",
            "–∫–æ–º–ø–∞–Ω–∏—è": "üí° –£–∑–Ω–∞–π –ø—Ä–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∫—É–ª—å—Ç—É—Ä—É",
            "–≤—Ä–µ–º—è": "üí° –ü—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞—Ç—ã",
            "—É–¥–∞–ª–µ–Ω–∫–∞": "üí° –£—Ç–æ—á–Ω–∏ –≥–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º"
        }
        
        user_lower = user_text.lower()
        for keyword, hint in hints.items():
            if keyword in user_lower:
                return hint
        
        return ""
    
    def _speak_ear_hint(self, hint: str):
        """–û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ "–≤ —É—Ö–æ" (—Ç–∏—à–µ)"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω–æ–π –≥—Ä–æ–º–∫–æ—Å—Ç—å—é
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                audio_data = loop.run_until_complete(self._generate_tts_audio(hint))
                
                # –ü–æ–Ω–∏–∂–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –¥–ª—è "–≤ —É—Ö–æ"
                audio_data = audio_data * 0.3  # 30% –≥—Ä–æ–º–∫–æ—Å—Ç–∏
                
                # –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º –Ω–∞ "–≤ —É—Ö–æ" –∫–∞–Ω–∞–ª–µ
                if self.ear_output_device is not None:
                    sd.play(audio_data, self.sample_rate, device=self.ear_output_device, blocking=True)
                
            finally:
                loop.close()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è –ø–æ–¥—Å–∫–∞–∑–∫–∏: {e}")
    
    def _pause_tts(self):
        """–ü–∞—É–∑–∞ TTS –ø—Ä–∏ –±–∞—Ä–¥–∂-–∏–Ω–µ"""
        self.tts_paused = True
        logger.info("‚è∏Ô∏è TTS –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–±–∞—Ä–¥–∂-–∏–Ω)")
    
    def _resume_tts(self):
        """–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ TTS"""
        self.tts_paused = False
        logger.info("‚ñ∂Ô∏è TTS –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω")
    
    def speak(self, text: str, ear_hint: str = ""):
        """–î–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è"""
        if text:
            self.tts_queue.put(text)
        
        if ear_hint:
            self.tts_queue.put(f"[–ü–û–î–°–ö–ê–ó–ö–ê] {ear_hint}")
    
    def start(self):
        """–ó–∞–ø—É—Å–∫ –¥—É–ø–ª–µ–∫—Å-—Ä–µ–∂–∏–º–∞"""
        if self.is_active:
            logger.warning("Voice Duplex —É–∂–µ –∞–∫—Ç–∏–≤–µ–Ω")
            return
        
        # –ù–∞—Ö–æ–¥–∏–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self._find_devices()
        
        if self.main_output_device is None:
            logger.error("–û—Å–Ω–æ–≤–Ω–æ–π –≤—ã—Ö–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        if self.mic_input_device is None:
            logger.error("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏
        self.stop_event.clear()
        
        # STT –ø–æ—Ç–æ–∫
        self.stt_thread = threading.Thread(target=self._stt_worker, daemon=True)
        self.stt_thread.start()
        
        # TTS –ø–æ—Ç–æ–∫
        self.tts_thread = threading.Thread(target=self._tts_worker, daemon=True)
        self.tts_thread.start()
        
        # "–í —É—Ö–æ" –ø–æ—Ç–æ–∫
        if self.ear_output_device is not None:
            self.ear_thread = threading.Thread(target=self._ear_worker, daemon=True)
            self.ear_thread.start()
        
        self.is_active = True
        logger.info("üéôÔ∏è Voice Duplex –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
    
    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥—É–ø–ª–µ–∫—Å-—Ä–µ–∂–∏–º–∞"""
        if not self.is_active:
            return
        
        self.stop_event.set()
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
        if self.stt_thread:
            self.stt_thread.join(timeout=2.0)
        if self.tts_thread:
            self.tts_thread.join(timeout=2.0)
        if self.ear_thread:
            self.ear_thread.join(timeout=2.0)
        
        self.is_active = False
        logger.info("üõë Voice Duplex –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞"""
        return {
            "is_active": self.is_active,
            "is_speaking": self.is_speaking,
            "is_user_speaking": self.is_user_speaking,
            "barge_in_active": self.barge_in_active,
            "tts_paused": self.tts_paused,
            "main_output": self.main_output_device,
            "ear_output": self.ear_output_device,
            "mic_input": self.mic_input_device
        }


# =============== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ===============

def test_voice_duplex():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Voice Duplex"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Voice Duplex...")
    
    def test_callback(text):
        print(f"üé§ –ü–æ–ª—É—á–µ–Ω–∞ —Ä–µ—á—å: {text}")
        return f"–ü–æ–Ω—è–ª: {text}"
    
    duplex = VoiceDuplex(response_callback=test_callback)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º
    duplex.start()
    
    print("üéôÔ∏è –î—É–ø–ª–µ–∫—Å-—Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–µ–Ω")
    print("üí¨ –ì–æ–≤–æ—Ä–∏—Ç–µ —Å AI, –æ–Ω –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å")
    print("üéß –ü–æ–¥—Å–∫–∞–∑–∫–∏ –±—É–¥—É—Ç –≤ '–≤ —É—Ö–æ' –∫–∞–Ω–∞–ª–µ")
    print("‚èπÔ∏è –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
    
    try:
        # –¢–µ—Å—Ç–æ–≤–æ–µ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ
        duplex.speak("–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ –∫ –¥–∏–∞–ª–æ–≥—É.")
        time.sleep(2)
        duplex.speak("–°–∫–∞–∂–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å, –∏ —è –æ—Ç–≤–µ—á—É.")
        
        # –ñ–¥–µ–º
        while True:
            time.sleep(1)
            status = duplex.get_status()
            if not status["is_active"]:
                break
                
    except KeyboardInterrupt:
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
    finally:
        duplex.stop()


if __name__ == "__main__":
    test_voice_duplex()
